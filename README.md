<p align="center">

<img src="assets/Illustration.jpg" alt="MMJ-Bench"/>

</p>

# MMJ-Bench
MMJ-Bench is a comprehensive benchmark designed to systematically evaluate existing multi-modal jailbreak attacks and defenses in a unified manner.


## Multi-model jailbreak attack
|                                                    **Method**                                                   |       **Source**      | **Key Properties**                                         | **Additional Notes**                                                    |
|:---------------------------------------------------------------------------------------------------------------:|:---------------------:|------------------------------------------------------------|-------------------------------------------------------------|
| FigStep | [FigStep: Jailbreaking Large Vision-language Models via Typographic Visual Prompts](https://arxiv.org/abs/2311.05608)  | Generation-based| |
| MM-SafetyBench | [MM-SafetyBench: A Benchmark for Safety Evaluation of Multimodal Large Language Models](https://arxiv.org/abs/2311.17600) | Generation-based| |
| VisualAdv | [Visual Adversarial Examples Jailbreak Aligned Large Language Models](https://ojs.aaai.org/index.php/AAAI/article/view/30150) | Optimization-based| |
| ImgJP | [Jailbreaking Attack against Multimodal Large Language Model](https://arxiv.org/abs/2402.02309) | Optimization-based | |
| AttackVLM | [On Evaluating Adversarial Robustness of Large Vision-Language Models](https://proceedings.neurips.cc/paper_files/paper/2023/hash/a97b58c4f7551053b0512f92244b0810-Abstract-Conference.html) | Geneation-based
| Hades | [Images are achilles’ heel of alignment: Exploiting visual vulnerabilities for jailbreaking multimodal large language models.](https://arxiv.org/abs/2403.09792) | Generation-based

Our evaluation results of MLLMs jailbreak attacks across six models are as follows:

<p align="center">

<img src="assets/ASR_eval_comparison_models.jpg" alt="ASR"/>

</p>





## Usage
### Installation
```
conda create -n MMJ-Bench python=3.10
conda create MMJ-Bench
pip install -r requirements.txt
```


The pipeline use in MMJ-Bench is the same as HarmBench.
### Step 1 - Generate Test Cases
The first step in the evaluation pipeline is generating test cases with `generate_test_cases.py`.
```
./scripts/generate_test_cases.sh $method_name $behaviors_path $save_dir
```


### Step 2 - Generate Completions
After generating test cases (attack prompts) specified by， we generate completions for a target model.
```
./scripts/generate_completions.sh $model_name $behaviors_path $test_cases_path $save_path $max_new_tokens $incremental_update
```

### Step 3 - Evaluate Completions
After generate completions from a `target_model` from Step 2, We will utilize the classifier provided by HarmBench to label whether each completion is an example of its corresponding behavior.
```
./scripts/evaluate_completions.sh $cls_path $behaviors_path $completions_path $save_path
```